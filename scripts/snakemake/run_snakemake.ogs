#!/bin/sh
#$ -cwd
#$ -N starsnakemake
#$ -m abe
#$ -M olneykimberly@mayo.edu
#$ -l h_vmem=2G
#$ -q 1-day,4-day,lg-mem
#$ -notify


# activate conda environment
source $HOME/.bash_profile
module load python
conda activate LBD

# change directory to where Snakefile is located
CWD="/research/labs/neurology/fryer/m239830/LBD_CWOW//scripts/snakemake"
cd $CWD

# run snakemake
snakemake -s Snakefile -j 250 --rerun-incomplete --latency-wait 15 --cluster "qsub -l h_vmem=8G -q 1-day,4-day,lg-mem -pe threaded 6"

# The submitted job will submit 28 sub-jobs (-j 28). You will see 29 jobs total with qstat.
# The main job requests 2 GB memory.
# Each sub-job requests 8 CPUs and 4GB memory (4GB x 8 threads).
# A grand total of 225 CPUs (main job + sub jobs) and 898 GB memory.

# For all blood, brain and kidney samples
# Wallclock Time   = 07:20:18
# CPU              = 00:00:19
# Max vmem         = 74.793M
