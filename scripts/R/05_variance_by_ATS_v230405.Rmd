---
title: "Variance in expression data"
author: "Kimberly Olney, Ph.D."
date: "04/05/2023"
output:
  html_document:
    df_print: paged
  pdf_document: default
params:
  args: myarg
---
# Setup
```{r setup}
knitr::opts_knit$set(root.dir = ".")
```

# User defined variables
```{r set_variables, warning=FALSE}
source(here::here("scripts/R", "file_paths_and_colours.R"))
source(here::here("scripts/R", "gtf_path.R"))
condition <- c("ATS.BIC2") #  TYPE
tool = c("star")
```
# Read in DGE object & metadata
```{r dge}
dge.filtered.norm <- readRDS(paste0("../../rObjects/dge.filtered.norm.rds"))
# some samples are missing RIN values. 
# Replace NA with median RIN. 
# This is necessary to be able include RIN as a covariate in voom
# fill missing values with median
dge.filtered.norm$samples$RIN <- impute(dge.filtered.norm$samples$RIN, median)
# one sample is missing VaD information
dge.filtered.norm$samples$VaD <- impute(dge.filtered.norm$samples$VaD, median)
dge.filtered.norm$samples$flowcell_and_lane <- factor(dge.filtered.norm$samples$flowcell_and_lane)
dge.filtered.norm$samples$APOE <- factor(dge.filtered.norm$samples$APOE)

info <- as.data.frame(dge.filtered.norm$samples)
genes <- dge.filtered.norm$genes
```

# BIC with forward stepwise regression
First, we will scale some of the continuous variables. 
In regression, it is often recommended to scale the features so that the predictors have a mean of 0. This makes it easier to interpret the intercept term as the expected value of Y when the predictor values are set to their means.
scale is generic function whose default method centers and/or scales the columns of a numeric matrix.

Secondly, obtian voom$E counts to use in the BIC. 
Finally, perform forwards stepwise regression Bayesian information criterion (BIC) to determine the best model. 
see: https://rdrr.io/github/GabrielHoffman/mvIC/man/mvIC_fit.html 
```{r scale}
scaled.info <-
  info[c(
    "Race_numeric",
    "RIN",
    "Age",
    "PCT_CODING_BASES",
    "PCT_INTERGENIC_BASES",
    "PCT_INTRONIC_BASES",
    "APOE_E4_allele_count"
  )] %>% scale()
scaled.info.df <- as.data.frame(scaled.info)
# Add scaled information to the metadata called "info"
info_with_scale <- cbind(info, scaled.info.df)
dge.filtered.norm$samples. <- info_with_scale
```
Voom transform counts to use for BIC 
```{r voom, warning=FALSE}
formula <- (~ 0 + ATS_names)
voom_with_weights <-
  variancePartition::voomWithDreamWeights(
    counts = dge.filtered.norm$counts,
    formula = formula,
    data = dge.filtered.norm$samples,
    BPPARAM = BiocParallel::SnowParam(cores),
    plot = TRUE
  )
path <- paste0("../../results/", tool, "/voom/", condition, ".raw.voom")
saveToPDF(paste0(path, ".pdf"), width = 6, height = 4)
voomCounts <- voom_with_weights$E
```
```{r BIC, eval = FALSE}
baseFormula <- ~ (1 | ATS_names)
# Combine responses on *rows*
Y = with(
  info,
  rbind(
    sex_inferred,
    Race,
    flowcell_and_lane,
    APOE,
    scaled.info.df$RIN,
    scaled.info.df$Age,
    scaled.info.df$APOE_E4_allele_count,
    scaled.info.df$PCT_CODING_BASES,
    scaled.info.df$PCT_INTERGENIC_BASES,
    scaled.info.df$PCT_INTRONIC_BASES, 
    Astrocyte.Zscore,
    Endothelial.Zscore,
    Microglia.Zscore,
    Mural.Zscore,
    Neuron_All.Zscore,
    Neuron_Interneuron.Zscore, 
    Neuron_Projection.Zscore,
    Oligodendrocyte.Zscore,
    Oligodendrocyte_Immature.Zscore,
    RBC.Zscore
  )
)

rownames(Y) <-
  c(
    "sex_inferred",
    "Race",
    "flowcell_and_lane",
    "APOE",
    "RIN",
    "Age",
    "APOE_E4_allele_count",
    "PCT_CODING_BASES",
    "PCT_INTERGENIC_BASES",
    "PCT_INTRONIC_BASES",
    "Astrocyte.Zscore",
    "Endothelial.Zscore",
    "Microglia.Zscore",
    "Mural.Zscore",
    "Neuron_All.Zscore",
    "Neuron_Interneuron.Zscore", 
    "Neuron_Projection.Zscore",
    "Oligodendrocyte.Zscore",
    "Oligodendrocyte_Immature.Zscore",
    "RBC.Zscore"
  )
# variables to consider in the model
# categorical variables must be modeled using (1|)
variables = c(
  "(1|sex_inferred)",
  "(1|Race)",
  "(1|flowcell_and_lane)",
  "(1|APOE)",
  "RIN",
  "Age",
  "APOE_E4_allele_count",
  "PCT_CODING_BASES",
  "PCT_INTERGENIC_BASES",
  "PCT_INTRONIC_BASES",
  "Astrocyte.Zscore",
  "Endothelial.Zscore",
  "Microglia.Zscore",
  "Mural.Zscore",
  "Neuron_All.Zscore",
  "Neuron_Interneuron.Zscore", 
  "Neuron_Projection.Zscore",
  "Oligodendrocyte.Zscore",
  "Oligodendrocyte_Immature.Zscore",
  "RBC.Zscore"
)

# fit forward stepwise regression starting
bestModel_voomcounts = mvForwardStepwise(voomCounts,
                                         baseFormula,
                                         data = info,
                                         variables = variables)
bestModel_voomcounts
```
Only protein coding genes:
  Best model: ~ (1 | TYPE) + PCT_CODING_BASES + (1 | flowcell_and_lane) + (1 | sex_inferred) + PCT_INTRONIC_BASES + PCT_INTERGENIC_BASES + RIN + Age 

Only protein coding genes with cell Type zscore: 
  ~ (1 | TYPE) + Neuron_Interneuron.Zscore + Neuron_Projection.Zscore + Mural.Zscore + (1 | sex_inferred) + Oligodendrocyte.Zscore + (1 | flowcell_and_lane) + Astrocyte.Zscore + Microglia.Zscore + PCT_CODING_BASES + Endothelial.Zscore + Neuron_All.Zscore + RIN + Oligodendrocyte_Immature.Zscore + PCT_INTERGENIC_BASES + PCT_INTRONIC_BASES + RBC.Zscore + (1 | Race)

All genes:
Best model: ~ (1 | TYPE) + PCT_CODING_BASES + RIN + (1 | flowcell_and_lane) + PCT_INTRONIC_BASES + PCT_INTERGENIC_BASES + (1 | sex_inferred) + (1 | APOE) 

ATS with cell types 
Final model:
  ~ (1 | ATS_names) + Neuron_Interneuron.Zscore + Neuron_Projection.Zscore + Mural.Zscore + (1 | sex_inferred) + Oligodendrocyte.Zscore + (1 | flowcell_and_lane) + Astrocyte.Zscore + PCT_INTRONIC_BASES
  
ATS with cell types including choroid 
Final model:
  ~ (1 | ATS_names) + Neuron_Interneuron.Zscore + Neuron_Projection.Zscore + Mural.Zscore + (1 | sex_inferred) + Oligodendrocyte.Zscore + (1 | flowcell_and_lane) + Astrocyte.Zscore + Neuron_All.Zscore + Oligodendrocyte_Immature.Zscore
# Design matrix
```{r design}
design <-
  model.matrix(~ 0 + 
      ATS_names + 
      sex_inferred + 
      flowcell_and_lane + 
      Oligodendrocyte.Zscore +
      Neuron_Interneuron.Zscore + 
      Neuron_Projection.Zscore +
      Mural.Zscore +
      Astrocyte.Zscore +
      Neuron_All.Zscore +
      Oligodendrocyte_Immature.Zscore,
    dge.filtered.norm$samples
  )

colnames(design) <-
  c(
    "no_pathology",
    "amyloid",
    "amyloid_tau",
    "pure_synuclein",
    "low_amyloid_synuclein",
    "high_amyloid_synuclein",
    "amyloid_synuclein_tau",
    "sex",
    "Batch1",
    "Batch2",
    "Batch3",
    "Batch4",
    "Batch5",
    "Batch6",
    "Batch7",
    "Oligodendrocyte.Zscore",
    "Neuron_Interneuron.Zscore",
    "Neuron_Projection.Zscore",
    "Mural.Zscore", 
    "Astrocyte.Zscore", 
    "Neuron_All.Zscore",
    "Oligodendrocyte_Immature.Zscore"
  )
```
# Voom
When the library sizes are quite variable between samples, then the voom approach is theoretically more powerful than limma-trend. 
The voom method estimates the mean-variance relationship of the log-counts.
Generates a precision weight for each observation and enters these into the limma empirical Bayes analysis pipeline.
```{r voom_BIC}
form <- (
  ~ 0 +
      ATS_names + 
      sex_inferred + 
      flowcell_and_lane + 
      Oligodendrocyte.Zscore +
      Neuron_Interneuron.Zscore + 
      Neuron_Projection.Zscore +
      Mural.Zscore +
      Astrocyte.Zscore +
      Neuron_All.Zscore +
      Oligodendrocyte_Immature.Zscore
)

voom_cov <-
  variancePartition::voomWithDreamWeights(
    counts = dge.filtered.norm$counts,
    formula = form,
    data = dge.filtered.norm$samples,
    BPPARAM = BiocParallel::SnowParam(cores),
    plot = TRUE
  )
path <-
  paste0("../../results/",
         tool,
         "/voom/",
         condition,
         ".voom.model")
saveToPDF(paste0(path, ".pdf"), width = 6, height = 4)
voomCounts <- voom_cov$E
```
# Contrast plot
### pairwise ATS 
```{r contrasts}
# fits linear model for each gene given a series of arrays
fit <- lmFit(voom_cov, design)
coef.fit <- fit$coefficients

contrasts <- makeContrasts(
  amyloid_vs_no_pathology =  amyloid - no_pathology,
  amyloid_tau_vs_no_pathology = amyloid_tau - no_pathology,
  low_amyloid_synuclein_vs_no_pathology = low_amyloid_synuclein - no_pathology,
  high_amyloid_synuclein_vs_no_pathology = high_amyloid_synuclein - no_pathology,
  amyloid_synuclein_tau_vs_no_pathology = amyloid_synuclein_tau - no_pathology,
 
  amyloid_tau_vs_amyloid = amyloid_tau - amyloid,
  low_amyloid_synuclein_vs_amyloid = low_amyloid_synuclein - amyloid,
  high_amyloid_synuclein_vs_amyloid = high_amyloid_synuclein - amyloid,
  amyloid_synuclein_tau_vs_amyloid = amyloid_synuclein_tau - amyloid,

  low_amyloid_synuclein_vs_amyloid_tau = low_amyloid_synuclein - amyloid_tau,
  high_amyloid_synuclein_vs_amyloid_tau = high_amyloid_synuclein - amyloid_tau,
  amyloid_synuclein_tau_vs_amyloid_tau = amyloid_synuclein_tau - amyloid_tau,
  
  high_amyloid_synuclein_vs_low_amyloid_synuclein = high_amyloid_synuclein - low_amyloid_synuclein,
  amyloid_synuclein_tau_vs_low_amyloid_synuclein = amyloid_synuclein_tau - low_amyloid_synuclein,
  
  amyloid_synuclein_tau_vs_high_amyloid_synuclein = amyloid_synuclein_tau - high_amyloid_synuclein,

  levels = colnames(design))
head(contrasts)

# save contrast names
allComparisons <- colnames(contrasts)
allComparisons # check

# run contrast analysis
vfit <- contrasts.fit(fit, contrasts = contrasts)

# Compute differential expression based on the empirical Bayes moderation of the
# standard errors towards a common value.
# The logCPM values can then be used in any standard limma pipeline, using the trend=TRUE
# argument when running eBayes or treat. For example:
veBayesFit <- eBayes(vfit, trend = TRUE, robust=TRUE)
plotSA(veBayesFit, main = "Final Model: Mean-variance Trend")
path <-
  paste0("../../results/",
         tool,
         "/voom/",
         condition,
         ".voom.eBayesFinalModel")
saveToPDF(paste0(path, ".pdf"), width = 8, height = 4)
# Rather than worry about the normalization too much, better to explore the data. E.g. try a BCV plot to look for dispersion outliers, or try robust=TRUE with eBayes() to downweight dispersion outliers. 

#disp <- estimateDisp(dge.filtered.norm, design, robust=TRUE)
#plotBCV(disp)
```

# DEGs summary
```{r DGE_summary}
pval <- 0.05
lfc.cutoff <- 0.25

sumTable <- 
  summary(decideTests(
    veBayesFit,  # object
    adjust.method = "BH", # by default the method = "separate"
    p.value = pval,
    lfc = lfc.cutoff  # numeric, minimum absolute log2-fold change required
  ))

print(paste0(" FDRq < ", pval,
             " & absolute log2-fold change > ", lfc.cutoff))
sumTable
write.table(sumTable, 
            paste0("../../results/", tool, "/DEGs/", condition, ".DEGs.summary.txt"), 
            quote = FALSE, sep = "\t")
```
# Add gene information to DEGs
reformat genes table to only include relevant information
```{r}
genes_relevant <- select(genes, 1:4,10:12)
```
Check AD vs Control
```{r DGE_check, eval=FALSE}
test <- topTable(
  veBayesFit, 
  coef = "amyloid_vs_no_pathology",  
  n = Inf, 
  p.value = 1,
  lfc = 0, 
  sort.by = "P", 
  genelist = genes_relevant, 
  confint = TRUE # column of confidence interval 
    )
#head(test, 20)
#subset(test, gene_name == "SNCB") 
```
# Save objects
```{r save_voom}
saveRDS(veBayesFit, file = paste0("../../rObjects/", condition, ".veBayesFit.rds"))
saveRDS(voomCounts, file = paste0("../../rObjects/", condition, ".voomCountsMatrix.rds"))
```
# Output DEG tables
```{r DGE_output}
coef <- 1

for (i in allComparisons) {
  vTopTableAll <- topTable(
    veBayesFit, 
    coef = coef,  
    n = Inf, 
    p.value = 1,
    lfc = 0, 
    sort.by = "P", 
    genelist = genes_relevant, 
    confint = TRUE # column of confidence interval 
    )
    saveRDS(vTopTableAll, file = 
            paste0("../../rObjects/gene_tables/", condition, "_", 
                   i,"_gene_table.rds"))
  path <- paste0("../../results/", tool, "/DEGs/", condition, "_", 
  i, "_gene_DEGs_FDRq1.00.txt", sep = "") 
  write.table(
    vTopTableAll,
    path,
    sep = "\t",
    row.names = FALSE,
    quote = FALSE
  )
  # p < 0.05, log2fc > 0
  vTopTable1 <-
    topTable( 
      veBayesFit,  
      coef = coef,  
      n = Inf, 
      p.value = pval,
      lfc = lfc.cutoff,
      genelist = genes_relevant, 
      confint = TRUE # column of confidence interval 
    )
  path <- paste0("../../results/", tool, "/DEGs/", condition, "_", 
  i, "_gene_DEGs_FDRq0.05_logFC_0.25.txt", sep = "") 
  write.table(
    vTopTable1,
    path,
    sep = "\t",
    row.names = FALSE,
    quote = FALSE
  )
  # increment 
  coef <- coef + 1
}
remove(coef)
```
# Fit variance 
variancePartition quantifies and interprets multiple sources of biological and technical variation in gene expression experiments. The package a linear mixed model to quantify variation in gene expression attributable to individual, tissue, time point, or technical variables.
Fit to the voomCounts_covariates
Repeat for the voomCounts without covariates added to the model 
```{r varpart}
form_varPart <- ~ (1|ATS_names) + 
  (1|sex_inferred) + 
  (1|flowcell_and_lane) +
  Oligodendrocyte.Zscore +
  Neuron_Interneuron.Zscore + 
  Neuron_Projection.Zscore +
  Mural.Zscore +
  Astrocyte.Zscore +
  Neuron_All.Zscore +
  Oligodendrocyte_Immature.Zscore

# fit model and extract variance percents
varPart <- fitExtractVarPartModel(voom_cov, form_varPart, info,
                                  showWarnings=FALSE)
```

```{r plot_variance}
varPart$gene_id <- NULL
plotVarPart(sortCols(varPart), label.angle = 80)
path <-
  paste0(
    "../../results/",
    tool,
    "/varpart/",
    condition,
    ".varpart"
  )
saveToPDF(paste0(path, ".pdf"), width = 10, height = 6)


# sort variables (i.e. columns) by median fraction # of variance explained
vp <- sortCols( varPart )
# Bar plot of variance fractions for the first 10 genes plotPercentBars( vp[1:10,] )
plotPercentBars( vp[1:10,] )

varPart$gene_id <- rownames(varPart)
# merge with gene information to get gene names for gene_id
variance_explained <- merge(varPart, genes, by = "gene_id")
write.table(
  variance_explained,
  paste0(
    "../../results/",
    tool ,
    "/varpart/",
    condition,
    ".variance.explained.tsv"
  ),
  sep = "\t",
  quote = FALSE
)
```

# CCA with the variables in the model 
canonical correspondence analysis (CCA) shows the relative effects of multiple variables
```{r CCA}
form <- ~ ATS_names + 
  sex_inferred + 
  flowcell_and_lane +
  Oligodendrocyte.Zscore +
  Neuron_Interneuron.Zscore + 
  Neuron_Projection.Zscore +
  Mural.Zscore +
  Astrocyte.Zscore +
  Neuron_All.Zscore +
  Oligodendrocyte_Immature.Zscore
  
C = canCorPairs( form, info)
# Plot correlation matrix
cor.mtest <- function(C, ...) {
    C <- as.matrix(C)
    n <- ncol(C)
    p.mat<- matrix(NA, n, n)
    diag(p.mat) <- 0
    for (i in 1:(n - 1)) {
        for (j in (i + 1):n) {
            tmp <- cor.test(C[, i], C[, j], ...)
            p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
        }
    }
  colnames(p.mat) <- rownames(p.mat) <- colnames(C)
  p.mat
}
# matrix of the p-value of the correlation
p.mat <- cor.mtest(C)
col <- colorRampPalette(c("#4477AA", "#77AADD", "#FFFFFF", "#EE9988", "#BB4444"))
  corrplot(C, method="color", col=col(200),  
         type="upper", order="hclust", 
         addCoef.col = "black", # Add coefficient of correlation
         tl.col="black", tl.srt=45, #Text label color and rotation
         diag=FALSE, col.lim = c(0, 1)
         )
path <- paste0("../../results/", tool ,"/varpart/", condition, "_CCA")
saveToPDF(paste0(path, ".pdf"), width = 10, height = 10)
```
# PCA
Principal component analysis, or PCA, is a dimensionality reduction method that is often used to reduce the dimensionality of large data sets, by transforming a large set of variables into a smaller one that still contains most of the information in the large set.
```{r PCA}
# Setting the N of genes to use
ntop = length(dge.filtered.norm$genes$gene_id)
# Sorting by the coefficient of variance
means <- rowMeans(voomCounts)
Pvars <- rowVars(voomCounts)
cv2 <- Pvars / means ^ 2
select <-
  order(cv2, decreasing = TRUE)[seq_len(min(ntop, length(cv2)))]
head(select)

highly_variable_exp <- ((voomCounts)[select,])
dim(highly_variable_exp)
# Running PCA
pca_exp <- prcomp(t(highly_variable_exp), scale = F, center = T)
# scale a logical value indicating whether the variables should be scaled
# to have unit variance before the analysis takes place.
# a logical value indicating whether the variables should be shifted to be zero centered.
head(pca_exp$x)[, 1:3]
summary(pca_exp)
# Dataframe with the first 10 PCs
dim1_10 <- data.frame(pca_exp$x[, 1:10])
# Adding metadata
dim1_10$NPID <- rownames(dim1_10)
pcaWithMetadata <- merge(dim1_10, info, by = "NPID", all = TRUE)
pcaWithMetadata$group <- pcaWithMetadata$ATS_names

# Plotting
ggplot(data = pcaWithMetadata, aes(x = PC1, y = PC2, shape = group, color = group)) +
  geom_point(size = 2.5) +
  theme_bw() +
  scale_color_manual(values = colorbindColors) 

ggplot(data = pcaWithMetadata, aes(x = PC2, y = PC3, shape = group, color = group)) +
  geom_point(size = 2.5) +
  theme_bw() +
  scale_color_manual(values = colorbindColors) 

ggplot(data = pcaWithMetadata, aes(x = PC3, y = PC4, shape = group, color = group)) +
  geom_point(size = 2.5) +
  theme_bw()

ggplot(data = pcaWithMetadata, aes(x = PC5, y = PC6, shape = sex_inferred, color = sex_inferred)) +
  geom_point(size = 2.5) 

```
# CCA PC1-10 & variables in model 
```{r CCA_PCA}
form_PCA <- ~ ATS_names + 
  sex_inferred + 
  flowcell_and_lane +
  Oligodendrocyte.Zscore +
  Neuron_Interneuron.Zscore + 
  Neuron_Projection.Zscore +
  Mural.Zscore +
  Astrocyte.Zscore +
  Neuron_All.Zscore +
  Oligodendrocyte_Immature.Zscore +
  PC1 +
  PC2 +
  PC3 +
  PC4 +
  PC5 +
  PC6 +
  PC7 +
  PC8 +
  PC9 +
  PC10 

C = canCorPairs(form_PCA, pcaWithMetadata)
# Plot correlation matrix
cor.mtest <- function(C, ...) {
    C <- as.matrix(C)
    n <- ncol(C)
    p.mat<- matrix(NA, n, n)
    diag(p.mat) <- 0
    for (i in 1:(n - 1)) {
        for (j in (i + 1):n) {
            tmp <- cor.test(C[, i], C[, j], ...)
            p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
        }
    }
  colnames(p.mat) <- rownames(p.mat) <- colnames(C)
  p.mat
}
# matrix of the p-value of the correlation
p.mat <- cor.mtest(C)
col <- colorRampPalette(c("#4477AA", "#77AADD", "#FFFFFF", "#EE9988", "#BB4444"))
  corrplot(C, method="color", col=col(200),  
         type="upper", order="hclust", 
         addCoef.col = "black", # Add coefficient of correlation
         tl.col="black", tl.srt=45, #Text label color and rotation
         diag=FALSE, col.lim = c(0, 1)
         )
path <- paste0("../../results/", tool ,"/varpart/", condition, ".CCA_PC1_10")
saveToPDF(paste0(path, ".pdf"), width = 20, height = 20)
```

# Correlation heatmap
scale() function is used to ensure that variables measured in different scales (e.g. age of death vs RIN) are comparable.
same results with and without the use of scale
```{r corr_heatmap, eval=FALSE}
cor_mat <- rcorr(as.matrix(C))

corrplot(
  cor_mat$r,
  method = "color",
  col = correlationColors(200),
  type = "upper",
  order = "hclust",
  p.mat = cor_mat$P,
  addCoef.col = "black",
  # Add coefficient of correlation
  tl.col = "black",
  tl.srt = 45,
  #Text label color and rotation
  diag = FALSE,
  col.lim = c(-1, 1)
)
path <- paste0("../../results/", tool ,"/varpart/", condition, ".CCA_PC1_10_sig")
saveToPDF(paste0(path, ".pdf"), width = 15, height = 15)
```

```{r}
sessionInfo()
```